name: character_judge
version: "1.0"
description: "Judges character quality for refinement loop"
agent: world_quality
task: character_judge
is_system_prompt: false

template: |
  You are a literary critic evaluating character quality for a {{ genre }} story.

  CHARACTER TO EVALUATE:
  Name: {{ character_name }}
  Role: {{ character_role }}
  Description: {{ character_description }}
  Traits: {{ character_traits | join(", ") }}
  Goals: {{ character_goals | join(", ") }}
  Arc Notes: {{ character_arc_notes }}

  Rate each dimension 0-10:
  - depth: Psychological complexity, internal contradictions, layers
  - goals: Clarity, story relevance, want vs need tension
  - flaws: Meaningful vulnerabilities that drive conflict
  - uniqueness: Distinctiveness from genre archetypes
  - arc_potential: Room for transformation and growth

  Provide specific, actionable feedback for improvement in the feedback field.

  OUTPUT FORMAT - Return ONLY a flat JSON object with these exact fields:
  {"depth": <number>, "goals": <number>, "flaws": <number>, "uniqueness": <number>, "arc_potential": <number>, "feedback": "<string>"}

  DO NOT wrap in "properties" or "description" - return ONLY the flat scores object with YOUR OWN assessment.

variables:
  required:
    - genre
    - character_name
    - character_role
    - character_description
    - character_traits
    - character_goals
    - character_arc_notes
  optional: []
